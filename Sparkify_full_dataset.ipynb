{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "owned-discount",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3294fb57376e44719c5fbcc4b80c7513",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>0</td><td>application_1618666845340_0008</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-172-31-14-96.us-east-2.compute.internal:20888/proxy/application_1618666845340_0008/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-172-31-0-186.us-east-2.compute.internal:8042/node/containerlogs/container_1618666845340_0008_01_000001/livy\">Link</a></td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import libraries\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import avg, col, concat, desc, lit, min, max, split, udf, countDistinct, sum, count, isnan, when, count, col, size\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import array, lit\n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler, OneHotEncoderEstimator\n",
    "from pyspark.ml.classification import LogisticRegression, DecisionTreeClassifier,RandomForestClassifier, LinearSVC\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.pipeline import PipelineModel\n",
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "verbal-candy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e60cb686121149b8aeb426a6ad4b6f14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(artist='Popol Vuh', auth='Logged In', firstName='Shlok', gender='M', itemInSession=278, lastName='Johnson', length=524.32934, level='paid', location='Dallas-Fort Worth-Arlington, TX', method='PUT', page='NextSong', registration=1533734541000, sessionId=22683, song='Ich mache einen Spiegel - Dream Part 4', status=200, ts=1538352001000, userAgent='\"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/36.0.1985.143 Safari/537.36\"', userId='1749042')"
     ]
    }
   ],
   "source": [
    "# Starter code\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create spark session\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Sparkify\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Read in full sparkify dataset\n",
    "event_data = \"s3n://udacity-dsnd/sparkify/sparkify_event_data.json\"\n",
    "df = spark.read.json(event_data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "opened-smart",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fceaecfa2dba4b618e8ea1354bb240e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def clean_dataset(event_data):\n",
    "    \n",
    "    '''\n",
    "    Take a event_data as a path to a spark dataframe in the json format. Selects the columns that will be used\n",
    "    in the model, cleans the data, create dummies for the categoricals, create the date columns, balance\n",
    "    the dataframe and outputs a model dataframe.\n",
    "\n",
    "    Parameters:\n",
    "    event_data : the path to the dataframe in the spark session in the format json (ex: 'mini_sparkify_event_data.json')\n",
    "\n",
    "    Returns cleaned and balanced spark dataframe.\n",
    "    '''\n",
    "\n",
    "    \n",
    "    df = spark.read.json(event_data)\n",
    "    #selecting only the columns that will be used\n",
    "    df=df.select(['gender', 'auth','page', 'ts', 'level', 'userId', 'page','registration'])\n",
    "\n",
    "    #removing the guest and logged Out\n",
    "    df_filtered = df.filter((df.auth != 'Guest') & (df.auth != 'Logged Out'))\n",
    "\n",
    "    #Creating the churn column as a dummy\n",
    "    cancelled = udf(lambda x : 0 if  x == 'Logged In' else 1, IntegerType())\n",
    "    df_clean = df_filtered.withColumn('churn',cancelled('auth'))\n",
    "\n",
    "    # Creating a new column with the page column as 1 if the user is downgraded\n",
    "    downgrade = udf(lambda x : 1 if  x == 'Submit Downgrade' else 0, IntegerType())\n",
    "    df_clean = df_clean.withColumn('Downgrade',downgrade('page'))\n",
    "\n",
    "\n",
    "    #creating the date column\n",
    "    df_clean = df_clean.withColumn(\"date\", F.to_date(F.from_unixtime(col('ts')/lit(1000))))\n",
    "    df_clean = df_clean.withColumn(\"date_created\", F.to_date(F.from_unixtime(col('registration')/lit(1000))))\n",
    "    df_clean = df_clean.withColumn(\"time_from_creation\", F.datediff('date','date_created'))\n",
    "\n",
    "    # Convert gender to binary. 1 = female\n",
    "    female = udf(lambda x: 1 if x == 'F' else 0, IntegerType())\n",
    "    df_clean = df_clean.withColumn('gender_binary', female('gender'))\n",
    "\n",
    "    # Convert level to binary. 1 = paid\n",
    "    level = udf(lambda x: 1 if x == 'paid' else 0, IntegerType())\n",
    "    df_clean = df_clean.withColumn('paid_user', level('level'))\n",
    "\n",
    "    # Convert songs played to binary.\n",
    "    songs = udf(lambda x: 1 if x == 'NextSong' else 0, IntegerType())\n",
    "    df_clean = df_clean.withColumn('played_song', songs('page'))\n",
    "\n",
    "    # Get user interactions except for playing songs\n",
    "    inter = ['Thumbs Up', 'Thumbs Down', 'Add to Playlist', 'Add Friend']\n",
    "    get_interactions = udf(lambda x: 1 if x in inter else 0, IntegerType())\n",
    "    df_clean = df_clean.withColumn('interactions', get_interactions('page'))\n",
    "\n",
    "\n",
    "    # Get the model\n",
    "    model_df = df_clean.groupby('userId').agg(\\\n",
    "                                                              max('churn').alias('churn_rate'),\\\n",
    "                                                              max('Downgrade').alias('Downgrade'),\\\n",
    "                                                              avg('time_from_creation').alias('time_from_creation'),\\\n",
    "                                                              max('gender_binary').alias('gender'),\\\n",
    "                                                              max('paid_user').alias('paid_user'),\\\n",
    "                                                              sum('played_song').alias('total_songs_played'),\\\n",
    "                                                              sum('interactions').alias('interactions'),\\\n",
    "                                             max('date').alias('date'),\\\n",
    "                                             max('date_created').alias('date_created'))\n",
    "\n",
    "\n",
    "\n",
    "    #Create a column with the session time and dropping the date column\n",
    "    model_df = model_df.withColumn(\"session_time\", F.datediff('date','date_created'))\n",
    "    model_df = model_df.drop('date')\n",
    "    \n",
    "    #Ensuring that users with low interactions are considered as churned\n",
    "    model_df = model_df.withColumn(\"churn_rate\", \\\n",
    "              F.when( (model_df[\"churn_rate\"]==1) | (model_df[\"interactions\"] < 2), 1).otherwise(0))\n",
    "    \n",
    "    #Balancing the dataframe by the churn rate\n",
    "    numerator = model_df.filter(model_df.churn_rate == 1).count()\n",
    "    churned =  model_df.filter(model_df.churn_rate == 1)\n",
    "    not_churned= model_df.filter(model_df.churn_rate == 0)\n",
    "    denominator = not_churned.count()\n",
    "    sample_df = not_churned.sample(withReplacement=False, fraction=numerator/denominator, seed=42)\n",
    "    model_df = churned.union(sample_df)\n",
    "    \n",
    "\n",
    "    return model_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "miniature-canon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "573bec55e59f4ae18f0895c42573f2cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def model_preparation(model):\n",
    "        \n",
    "    '''\n",
    "    Take a model as a spark dataframe with this columns = ['Downgrade','time_from_creation','gender','paid_user',\n",
    "    'total_songs_played','interactions','session_time']. Uses the VectorAssembler on this columns and then uses\n",
    "    the StandardScaler on this numeric features.\n",
    "\n",
    "    Parameters:\n",
    "    model : a spark dataframe\n",
    "\n",
    "    Returns - Data prepared for machine learning with features and label columns.\n",
    "    '''\n",
    "    \n",
    "    # Assemble num features\n",
    "    assembler = VectorAssembler(inputCols=['Downgrade','time_from_creation','gender',\\\n",
    "                                       'paid_user','total_songs_played','interactions',\\\n",
    "                                      'session_time'],\\\n",
    "                            outputCol='numerical_features',handleInvalid = 'skip')\n",
    "    \n",
    "    #temp DF\n",
    "    temp = assembler.transform(model)\n",
    "    \n",
    "    #Create Scaler\n",
    "    scaler = StandardScaler(withMean=True, withStd=True, inputCol='numerical_features', outputCol='features')\n",
    "    scaler_fit = scaler.fit(temp)\n",
    "    \n",
    "    data = scaler_fit.transform(temp)\n",
    "    \n",
    "    # Use 'churn' as model prediction label\n",
    "    data = data.withColumnRenamed('churn_rate','label')\n",
    "    \n",
    "    return data\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "still-jamaica",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a05d0e9357c84862b51826f1270f7ec8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def baseline_ml(data):\n",
    "            \n",
    "    '''\n",
    "    Take the data as a processed spark dataframe. Splits the data into train and test. Use 4 machine learnirg\n",
    "    algorithms with the default settings: LogisticRegression, DecisionTreeClassifier(seed=42),\n",
    "    RandomForestClassifier(seed=42),LinearSVC. Outputs prints for the baseline parameters : accuracy. f1-score,\n",
    "    precision and recall.  \n",
    "    \n",
    "\n",
    "    Parameters:\n",
    "    model : a processed spark dataframe\n",
    "\n",
    "    Returns - Prints for the parameters\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    # Split train test set\n",
    "    train, test = data.randomSplit([0.8, 0.2], seed=42)\n",
    "    \n",
    "    # Initialize four models\n",
    "    clf_LR = LogisticRegression()\n",
    "    clf_DT = DecisionTreeClassifier(seed=42)\n",
    "    clf_RF = RandomForestClassifier(seed=42)\n",
    "    clf_SVM = LinearSVC()\n",
    "    \n",
    "    #Instanciate the evaluator\n",
    "    evaluator= MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "    \n",
    "    #Empty dic for the results\n",
    "    results = {}\n",
    "\n",
    "    for clf in [clf_LR, clf_DT, clf_RF, clf_SVM]:\n",
    "        model_results = {}\n",
    "        # get the classifier name\n",
    "        clf_name = clf.__class__.__name__\n",
    "\n",
    "        #Train\n",
    "        model = clf.fit(train)\n",
    "\n",
    "        #Predict\n",
    "        pred = model.transform(test)\n",
    "\n",
    "        #Get each model result, print and append to the results\n",
    "        model_results['f1_test'] = evaluator.evaluate(pred.select('label','prediction'),{evaluator.metricName: 'f1'})\n",
    "        model_results['precision'] = evaluator.evaluate(pred.select('label','prediction'),{evaluator.metricName: 'weightedPrecision'})\n",
    "        model_results['recall'] = evaluator.evaluate(pred.select('label','prediction'),{evaluator.metricName: 'weightedRecall'})\n",
    "        model_results['accuracy'] = evaluator.evaluate(pred.select('label','prediction'),{evaluator.metricName: 'accuracy'})\n",
    "\n",
    "        print(clf_name)\n",
    "        print('Test F1-score: ',model_results['f1_test'])\n",
    "        results[clf_name] = model_results\n",
    "    \n",
    "    \n",
    "    return results\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cubic-disclaimer",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a713dce37dd84a63acc802981fd72c7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "model = clean_dataset(event_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "headed-naples",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96afb7b56c264c57ad6ccefe996f0ca9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = model_preparation(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "organic-behalf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread cell_monitor-8:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/awseditorssparkmonitoringwidget-1.0-py3.7.egg/awseditorssparkmonitoringwidget/cellmonitor.py\", line 178, in cell_monitor\n",
      "    job_binned_stages[job_id][stage_id] = all_stages[stage_id]\n",
      "KeyError: 1258\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression\n",
      "Test F1-score:  0.7472126221248947\n",
      "DecisionTreeClassifier\n",
      "Test F1-score:  0.7320726580584135\n",
      "RandomForestClassifier\n",
      "Test F1-score:  0.7237304651485719\n",
      "LinearSVC\n",
      "Test F1-score:  0.7536315575929698\n",
      "{'LogisticRegression': {'f1_test': 0.7472126221248947, 'precision': 0.7479786013340562, 'recall': 0.7484076433121019, 'accuracy': 0.7429481346678799}, 'DecisionTreeClassifier': {'f1_test': 0.7320726580584135, 'precision': 0.7599060310646791, 'recall': 0.7333939945404914, 'accuracy': 0.7402183803457689}, 'RandomForestClassifier': {'f1_test': 0.7237304651485719, 'precision': 0.7561078172995626, 'recall': 0.732484076433121, 'accuracy': 0.7333939945404914}, 'LinearSVC': {'f1_test': 0.7536315575929698, 'precision': 0.7495968605071163, 'recall': 0.7506824385805277, 'accuracy': 0.7493175614194723}}"
     ]
    }
   ],
   "source": [
    "baseline_ml(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "lined-butterfly",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7df403953224a4a916f6362f496f677",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get the params\n",
    "\n",
    "clf_LR = LogisticRegression()\n",
    "paramGrid = ParamGridBuilder().\\\n",
    "            addGrid(clf_LR.maxIter, [10, 100, 1000]).\\\n",
    "            addGrid(clf_LR.regParam, [0.01,0.1,10.0,100.0]).\\\n",
    "            build()\n",
    "\n",
    "#Use the crossvalidation\n",
    "crossval = CrossValidator(estimator=clf_LR,\n",
    "                      estimatorParamMaps=paramGrid,\n",
    "                      evaluator=MulticlassClassificationEvaluator(metricName=\"f1\"),\n",
    "                      numFolds=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "loaded-walter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "234e5ad1b1e5411fb338628f46f477a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread cell_monitor-10:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/awseditorssparkmonitoringwidget-1.0-py3.7.egg/awseditorssparkmonitoringwidget/cellmonitor.py\", line 178, in cell_monitor\n",
      "    job_binned_stages[job_id][stage_id] = all_stages[stage_id]\n",
      "KeyError: 1495\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Train model\n",
    "train, test = data.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "\n",
    "cvModel_stack = crossval.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "artificial-developer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28641ee9438545709144c8fa89e8a6a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Predict\n",
    "\n",
    "pred = cvModel_stack.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "gross-russian",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "438e56ca3ca04911b623c2296b41affa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-1 Score:0.7435218879141079"
     ]
    }
   ],
   "source": [
    "# Results\n",
    "evaluator= MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "print('F-1 Score:{}'.format(evaluator.evaluate(pred.select('label','prediction'), {evaluator.metricName: \"f1\"})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "mineral-banner",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcc7f03cfbe54cdcad4e40ee2e51a1d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Param (regParam):  0.01\n",
      "Best Param (MaxIter):  10\n",
      "Best Param (elasticNetParam):  0.0"
     ]
    }
   ],
   "source": [
    "# Get the best params\n",
    "bestModel = cvModel_stack.bestModel\n",
    "print ('Best Param (regParam): ', bestModel._java_obj.getRegParam())\n",
    "\n",
    "print ('Best Param (MaxIter): ', bestModel._java_obj.getMaxIter())\n",
    "\n",
    "print ('Best Param (elasticNetParam): ', bestModel._java_obj.getElasticNetParam())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "celtic-interval",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "789ca2340ab240c9b65e6433335d74be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get the params\n",
    "\n",
    "clf_SVM = LinearSVC()\n",
    "paramGrid = ParamGridBuilder().\\\n",
    "            addGrid(clf_SVM.maxIter, [10, 100, 1000]).\\\n",
    "            addGrid(clf_SVM.regParam, [0.01,0.1,10.0,100.0]).\\\n",
    "            build()\n",
    "\n",
    "#Use the crossvalidation\n",
    "crossval = CrossValidator(estimator=clf_SVM,\n",
    "                      estimatorParamMaps=paramGrid,\n",
    "                      evaluator=MulticlassClassificationEvaluator(metricName=\"f1\"),\n",
    "                      numFolds=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "motivated-samoa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28c1e6ff053c403bae5ec8d8b33530fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread cell_monitor-9:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/awseditorssparkmonitoringwidget-1.0-py3.7.egg/awseditorssparkmonitoringwidget/cellmonitor.py\", line 178, in cell_monitor\n",
      "    job_binned_stages[job_id][stage_id] = all_stages[stage_id]\n",
      "KeyError: 1596\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Train model\n",
    "train, test = data.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "\n",
    "cvModel_stack = crossval.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "demanding-musical",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e41294ad887b468c857f032a73a241d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Predict\n",
    "\n",
    "pred = cvModel_stack.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "unsigned-alias",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6630e6c941084b999ee7a8307a7e2886",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-1 Score:0.755621576663529"
     ]
    }
   ],
   "source": [
    "# Results\n",
    "evaluator= MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "print('F-1 Score:{}'.format(evaluator.evaluate(pred.select('label','prediction'), {evaluator.metricName: \"f1\"})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "sunset-centre",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc30d33369d84789a208a8a03174f1ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Param (regParam):  0.01\n",
      "Best Param (MaxIter):  100"
     ]
    }
   ],
   "source": [
    "# Get the best params\n",
    "bestModel = cvModel_stack.bestModel\n",
    "print ('Best Param (regParam): ', bestModel._java_obj.getRegParam())\n",
    "\n",
    "print ('Best Param (MaxIter): ', bestModel._java_obj.getMaxIter())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inappropriate-shopper",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alive-cabin",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 2
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
